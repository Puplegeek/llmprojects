{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a473d607-073d-4963-bdc4-aba654523681",
   "metadata": {},
   "source": [
    "## Day 2 Exercise\n",
    "building upon the day1 exercise to offer a multi models via dropdown.\n",
    "externalized the common methods into a AISystem.py file to be reused down the line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761729f-3bd5-4dd7-9e63-cbe6b4368a66",
   "metadata": {},
   "source": [
    "## Load env, check for api keys and load up the connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fedb3d94-d096-43fd-8a76-9fdbc2d0d78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyB9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from enum import Enum, auto\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from AISystem import formatPrompt, AI, AISystem\n",
    "import gradio as gr # oh yeah!\n",
    "\n",
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "openai_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "gemini_model = \"gemini-1.5-flash\"\n",
    "ollama_model = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7987b-2bdf-434a-8fce-6c367f148dde",
   "metadata": {},
   "source": [
    "## Create the systems for each llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f92eef29-325e-418c-a444-879d83d5fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "geminiSys = AISystem(gemini_via_openai_client,\n",
    "                        formatPrompt(\"system\",\"You are a chatbot. you always try to make conversation and get more in depth\"), \n",
    "                        gemini_model,\n",
    "                        AI.GEMINI)\n",
    "\n",
    "openAiSys = AISystem(openai,\n",
    "                        formatPrompt(\"system\",\"You are a chatbot. you always try to make conversation and get more in depth\"), \n",
    "                        openai_model,\n",
    "                        AI.OPEN_AI)\n",
    "\n",
    "claudeSys = AISystem(claude,\n",
    "                       \"You are a chatbot. you always try to make conversation and get more in depth\", \n",
    "                       claude_model,\n",
    "                        AI.CLAUDE)\n",
    "\n",
    "ollamaSys = AISystem(ollama_via_openai,\n",
    "                        formatPrompt(\"system\",\"You are a chatbot. you always try to make conversation and get more in depth\"), \n",
    "                        ollama_model,\n",
    "                        AI.OLLAMA)\n",
    "sys_dict = { AI.GEMINI: geminiSys, AI.OPEN_AI: openAiSys, AI.CLAUDE: claudeSys, AI.OLLAMA: ollamaSys}\n",
    "\n",
    "def stream_model(prompt, model):\n",
    "    aiSystem = sys_dict.get(AI[model.upper()])\n",
    "    yield from aiSystem.stream(formatPrompt(\"user\",prompt), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ecd283-92b2-454d-b1ae-8016d41e3026",
   "metadata": {},
   "source": [
    "## Create the gradio interface linking with the AI enum for the dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db8ed67-280a-400d-8543-4ab95863ce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_sync/connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_backends/sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 996, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/httpx/_transports/default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 2042, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1601, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/utils.py\", line 728, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/utils.py\", line 722, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 962, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/utils.py\", line 705, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/utils.py\", line 866, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/qw/ypkg96y167n6s6my1lxxphc00000gn/T/ipykernel_75527/858302501.py\", line 24, in stream_model\n",
      "    yield from aiSystem.stream(formatPrompt(\"user\",prompt), True)\n",
      "  File \"/Users/syedakash/Desktop/myllmprojects/llmprojects/week 02/community-contributions/AISystem.py\", line 70, in stream\n",
      "    stream = self.processor.chat.completions.create(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 279, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 859, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1283, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 960, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1098, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1020, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1098, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/openai/_base_client.py\", line 1030, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    inputs=[gr.Textbox(label=\"Your prompt:\", lines=6) , gr.Dropdown(choices=[ai.value for ai in AI], label=\"Select model\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23b939-6fdf-44d5-9d61-348e1d7c9732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
