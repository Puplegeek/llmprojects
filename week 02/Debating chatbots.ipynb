{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3349a5-f883-4fa9-a354-995ae1b9f720",
   "metadata": {},
   "source": [
    "**Multimodel conversation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07b544f-0986-43b2-b834-fbbc7cf33fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466ec9c3-ec7c-4ee5-85c8-d5427cd996cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "claude_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a1a694-a84d-4b1b-be82-06f2825b9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebateOrchestrator:\n",
    "    def __init__(self):\n",
    "        # Initialize clients\n",
    "        self.openai_client = OpenAI()\n",
    "        self.claude_client = anthropic.Anthropic()\n",
    "\n",
    "    def generate_system_prompts(self, topic, word_count, gpt_side, claude_side, gpt_personality, claude_personality):\n",
    "        gpt_system_prompt = (\n",
    "            f\"You are in a debate about {topic}. \"\n",
    "            f\"Respond with EXACTLY {word_count} words. \"\n",
    "            f\"You are the {gpt_side} side. \"\n",
    "            f\"Be concise, clear, and direct in your {word_count}-word counterargument. \"\n",
    "            f\"Your personality should be {gpt_personality}\"\n",
    "        )\n",
    "        \n",
    "        claude_system_prompt = (\n",
    "            f\"You are in a debate about {topic}. \"\n",
    "            f\"Respond with EXACTLY {word_count} words. \"\n",
    "            f\"You are the {claude_side} side. \"\n",
    "            f\"Be concise, clear, and direct in your {word_count}-word argument. \"\n",
    "            f\"Your personality should be {claude_personality}\"\n",
    "        )\n",
    "        \n",
    "        return gpt_system_prompt, claude_system_prompt\n",
    "\n",
    "    def call_gpt(self, claude_messages, gpt_system_prompt):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": gpt_system_prompt}\n",
    "        ]\n",
    "        \n",
    "        for claude_msg in claude_messages:\n",
    "            messages.append({\"role\": \"user\", \"content\": claude_msg})\n",
    "        \n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    def call_claude(self, gpt_messages, claude_system_prompt):\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": \"The topic is discussed\"}\n",
    "        ]\n",
    "        \n",
    "        for gpt_msg in gpt_messages:\n",
    "            messages.append({\"role\": \"user\", \"content\": gpt_msg})\n",
    "        \n",
    "        message = self.claude_client.messages.create(\n",
    "            model=\"claude-3-7-sonnet-20250219\",\n",
    "            max_tokens=100,\n",
    "            temperature=1,\n",
    "            system=claude_system_prompt,\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        return message.content[0].text\n",
    "\n",
    "    def conduct_streaming_debate(self, topic, word_count, gpt_side, claude_side, gpt_personality, claude_personality, num_rounds=5):\n",
    "        # Generate system prompts based on inputs\n",
    "        gpt_system_prompt, claude_system_prompt = self.generate_system_prompts(\n",
    "            topic, word_count, gpt_side, claude_side, gpt_personality, claude_personality\n",
    "        )\n",
    "        \n",
    "        gpt_messages = []\n",
    "        claude_messages = []\n",
    "        \n",
    "        # Yield initial setup message\n",
    "        yield f\"üèÅ Debate Topic: {topic}\\n\"\n",
    "        yield f\"üìè Word Count: {word_count}\\n\"\n",
    "        yield f\"ü§ñ Claude Side: {claude_side}\\n\"\n",
    "        yield f\"üíª GPT Side: {gpt_side}\\n\\n\"\n",
    "        \n",
    "        for round in range(num_rounds):\n",
    "            # Claude always goes first\n",
    "            yield f\"{'='*20} Round {round+1} {'='*20}\\n\"\n",
    "            \n",
    "            # Claude's turn\n",
    "            claude_response = self.call_claude(gpt_messages, claude_system_prompt)\n",
    "            claude_messages.append(claude_response)\n",
    "            \n",
    "            # Stream Claude's response\n",
    "            yield f\"Claude ({claude_side}, Round {round+1}): \"\n",
    "            for char in claude_response:\n",
    "                yield char\n",
    "                time.sleep(0.02)\n",
    "            yield \"\\n\\n\"\n",
    "            \n",
    "            # GPT's turn\n",
    "            yield f\"GPT ({gpt_side}, Round {round+1}): \"\n",
    "            gpt_response = self.call_gpt(claude_messages, gpt_system_prompt)\n",
    "            gpt_messages.append(gpt_response)\n",
    "            \n",
    "            # Stream GPT's response\n",
    "            for char in gpt_response:\n",
    "                yield char\n",
    "                time.sleep(0.02)\n",
    "            yield \"\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ceebec-ea57-41f2-9193-7a595f186d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_gradio_interface():\n",
    "    orchestrator = DebateOrchestrator()\n",
    "    \n",
    "    def run_debate(topic, word_count, gpt_side, claude_side, gpt_personality, claude_personality, rounds):\n",
    "        # Wrap the generator in a list to ensure compatibility\n",
    "        return ''.join(\n",
    "            orchestrator.conduct_streaming_debate(\n",
    "                topic, word_count, gpt_side, claude_side, \n",
    "                gpt_personality, claude_personality, \n",
    "                num_rounds=rounds\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Create Gradio interface\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# Chatbot Debate Simulator\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Topic input (text box without predefined value)\n",
    "            topic_input = gr.Textbox(label=\"Debate Topic\", interactive=True)\n",
    "            \n",
    "            # Word count input (number input)\n",
    "            word_count_input = gr.Number(label=\"Word Count per Response\", interactive=True)\n",
    "        \n",
    "        with gr.Row():\n",
    "            # GPT Side dropdown\n",
    "            gpt_side_input = gr.Dropdown(\n",
    "                label=\"GPT Side\", \n",
    "                choices=[\"Affirmative\", \"Opposition\"], \n",
    "                interactive=True\n",
    "            )\n",
    "            \n",
    "            # Claude Side dropdown\n",
    "            claude_side_input = gr.Dropdown(\n",
    "                label=\"Claude Side\", \n",
    "                choices=[\"Affirmative\", \"Opposition\"], \n",
    "                interactive=True\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            # GPT Personality (text box without predefined value)\n",
    "            gpt_personality_input = gr.Textbox(label=\"GPT Personality\", interactive=True)\n",
    "            \n",
    "            # Claude Personality (text box without predefined value)\n",
    "            claude_personality_input = gr.Textbox(label=\"Claude Personality\", interactive=True)\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Number input for rounds\n",
    "            rounds_input = gr.Number(label=\"Number of Rounds\", interactive=True)\n",
    "        \n",
    "        # Debate output with streaming\n",
    "        debate_output = gr.Textbox(label=\"Debate Transcript\", interactive=False)\n",
    "        \n",
    "        # Run debate button\n",
    "        run_button = gr.Button(\"Start Debate\")\n",
    "        run_button.click(\n",
    "            fn=run_debate, \n",
    "            inputs=[\n",
    "                topic_input, word_count_input, \n",
    "                gpt_side_input, claude_side_input, \n",
    "                gpt_personality_input, claude_personality_input, \n",
    "                rounds_input\n",
    "            ], \n",
    "            outputs=debate_output\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo = create_gradio_interface()\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15c92f-5d60-409f-b677-41dad4cc6b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
